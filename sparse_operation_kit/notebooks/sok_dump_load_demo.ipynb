{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdfec37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2024 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "# Each user is responsible for checking the content of datasets and the\n",
    "# applicable licenses and determining if suitable for the intended use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4337359",
   "metadata": {},
   "source": [
    "<img src=\"http://developer.download.nvidia.com/notebooks/dlsw-notebooks/merlin_hugectr_hps-sok-to-dlrm-demo/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# SOK DUMP/LOAD Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ac179f",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook demonstrates how to use SOK to dump/load parallel-trained embedding weights to/from the filesystem, and to verify the correctness of sok's load and dump operations. You can learn how to use sok.dump, sok.load, sok.export, sok.assign in this demo. \n",
    "\n",
    "For more details about SOK, please refer to [SOK Documentation](https://nvidia-merlin.github.io/HugeCTR/sparse_operation_kit/master/index.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202109ad",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "### Get SOK from NGC\n",
    "\n",
    "SOK Python modules are preinstalled in the 23.12 and later [Merlin Tensorflow Container](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/merlin/containers/merlin-tensorflow): `nvcr.io/nvidia/merlin/merlin-tensorflow:nightly`.\n",
    "\n",
    "You can check the existence of the required libraries by running the following Python code after launching this container.\n",
    "\n",
    "```bash\n",
    "$ python3 -c \"import sparse_operation_kit as sok\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c936f7",
   "metadata": {},
   "source": [
    "## Configurations\n",
    "\n",
    "For demonstrating the SOK dump/load functionality, this demo shows the process of first dumping then loading after performing forward and backward with multiple SOK Variables paired with different TensorFlow Optimizers. This demo also verifies the correctness of the dump and load process.\n",
    "\n",
    "The operation method of this Notebook is based on [Introduction to Horovod](https://enccs.github.io/upscalingAIcontainer/hvd_intro/?highlight=jupyter#training-with-model-fit). The process is to first define the function, and then use horovod.run to execute it.\n",
    "\n",
    "In the first of all, we need to configure some SOK Variable properties and define a function for SOK forward and backward. This function takes SOK variables, lookup ids, and an optimizer to perform the tasks of forward, backward, and optimizer update for SOK variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c74eff6-6a27-4b23-a3eb-9559d0685ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import horovod\n",
    "import tensorflow as tf\n",
    "import horovod.tensorflow as hvd\n",
    "import numpy as np\n",
    "import sparse_operation_kit as sok\n",
    "rows = [8192 * 5, 8192]\n",
    "cols = [128, 4]\n",
    "hotness = [10, 3]\n",
    "combiners = [\"mean\", \"sum\"]\n",
    "batch_size = 8192\n",
    "iters = 100\n",
    "initial_vals = [13, 17]\n",
    "\n",
    "# train step\n",
    "def train_step(params, indices,sok_optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        embeddings = sok.lookup_sparse(params, indices, combiners=combiners)\n",
    "        loss = 0\n",
    "        for i in range(len(embeddings)):\n",
    "            loss = loss + tf.reduce_sum(embeddings[i])\n",
    "    grads = tape.gradient(loss, params)\n",
    "    sok_optimizer.apply_gradients(zip(grads, params))\n",
    "    loss = hvd.allreduce(loss, op=hvd.Sum)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a9a153-bf62-4d31-867b-517c40e0ef12",
   "metadata": {},
   "source": [
    "Define a function to evaluate SOK dump and load with a given optimizer. In this function, SOK first calls train_step for a forward and backward pass, then dumps the values in SOK Variables to the file system. Next, it sets the SOK Variables to 0, and then loads the values from the file system. Finally, it compares whether the values before and after dump and load are consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1f685fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sok_dump_load_evaluate(optimizer,optimizer_id):\n",
    "    sok_optimizer = sok.OptimizerWrapper(optimizer)\n",
    "    # sok variables\n",
    "    sok_vars = [\n",
    "        sok.DynamicVariable(dimension=cols[i],\n",
    "                            var_type=\"hybrid\",\n",
    "                            initializer=str(initial_vals[i]),\n",
    "                            init_capacity=1024 * 1024,\n",
    "                            max_capacity=1024 * 1024,)\n",
    "        for i in range(len(cols))\n",
    "    ]\n",
    "\n",
    "    #prepare lookup ids\n",
    "    local_indices = []\n",
    "    for row in rows:\n",
    "        local_size = row // hvd.size()\n",
    "        if hvd.rank() < row % hvd.size():\n",
    "            local_size += 1\n",
    "        indices = np.arange(local_size) * hvd.size() + hvd.rank()\n",
    "        indices = tf.convert_to_tensor(indices, dtype=tf.int64)\n",
    "        local_indices.append(indices)\n",
    "\n",
    "    total_indices = []\n",
    "    for i in range(len(rows)):\n",
    "        offsets = np.random.randint(1, hotness[i] + 1, iters * batch_size)\n",
    "        offsets = tf.convert_to_tensor(offsets, dtype=tf.int64)\n",
    "        offsets = hvd.broadcast(offsets, root_rank=0)\n",
    "        values = np.random.randint(0, rows[i], tf.reduce_sum(offsets))\n",
    "        values = tf.convert_to_tensor(values, dtype=tf.int64)\n",
    "        values = hvd.broadcast(values, root_rank=0)\n",
    "        total_indices.append(tf.RaggedTensor.from_row_lengths(values, offsets))\n",
    "    left = batch_size // hvd.size() * hvd.rank()\n",
    "    right = batch_size // hvd.size() * (hvd.rank() + 1)\n",
    "    indices = []\n",
    "    for j in range(len(total_indices)):\n",
    "        indices.append(total_indices[j][batch_size + left : batch_size + right])\n",
    "        \n",
    "    # Do forward and backward\n",
    "    _ = train_step(sok_vars, indices,sok_optimizer)\n",
    "\n",
    "    # Export all the embedding table and opt slot states to tf.variable \n",
    "    # so we can know the values of sok variables before sok.dump\n",
    "    # and after sok.load , we can compare values before sok.dump and load , and after sok.dump and load\n",
    "    vars_unique_ids = []\n",
    "    for sok_var in sok_vars:\n",
    "        vars_unique_ids.append(sok_var._unique_id)\n",
    "    #check optimizer have train state\n",
    "    have_state = True\n",
    "    for vars_unique_id in vars_unique_ids:\n",
    "        tmp_slot = optimizer._slots.get(vars_unique_id)\n",
    "        if tmp_slot == None:\n",
    "            have_state = False\n",
    "            break\n",
    "    slot_names = optimizer.get_slot_names()\n",
    "    slot_states_list_raw = []\n",
    "    slot_states_index_list_raw = []\n",
    "    slot_vars_list = []\n",
    "    if have_state:\n",
    "        for slot_name in slot_names:\n",
    "            slot_vars_np_list_raw = []\n",
    "            slot_vars_index_np_list_raw = []\n",
    "            tmp_slot_var_list = []\n",
    "            for sok_var in sok_vars:\n",
    "                slot_var = optimizer.get_slot(sok_var, slot_name)\n",
    "                ex_indices, ex_values = sok.export(slot_var)\n",
    "                slot_vars_np_list_raw.append(ex_values.numpy())\n",
    "                slot_vars_index_np_list_raw.append(ex_indices.numpy())\n",
    "                tmp_slot_var_list.append(slot_var)\n",
    "            slot_states_list_raw.append(slot_vars_np_list_raw)\n",
    "            slot_states_index_list_raw.append(slot_vars_index_np_list_raw)\n",
    "            slot_vars_list.append(tmp_slot_var_list)\n",
    "\n",
    "    sok_var_nps_raw = []\n",
    "    sok_var_index_nps_raw = []\n",
    "    sok_var_nps_new = []\n",
    "    sok_var_index_nps_new = []\n",
    "\n",
    "    for sok_var in sok_vars:\n",
    "        ex_indices, ex_values = sok.export(sok_var)\n",
    "        sok_var_nps_raw.append(ex_values.numpy())\n",
    "        sok_var_index_nps_raw.append(ex_indices.numpy())\n",
    "    #Export all the embedding table and opt slot states to tf.variable Done!\n",
    "    \n",
    "    # Dump sok variable and opt slot states to file system    \n",
    "    sok.dump(\"./weight\", sok_vars, sok_optimizer)\n",
    "\n",
    "\n",
    "    # Assign all the sok_var to zero , like a memset , so we can make sure load is valid\n",
    "    for sok_var in sok_vars:\n",
    "        ex_indices, ex_values = sok.export(sok_var)\n",
    "        zeros_values = tf.zeros(ex_values.shape)\n",
    "        sok.assign(sok_var, ex_indices, zeros_values)\n",
    "\n",
    "    \n",
    "    for tmp_slot_list in slot_vars_list:\n",
    "        for tmp_slot_var in tmp_slot_list:\n",
    "            ex_indices, ex_values = sok.export(tmp_slot_var)\n",
    "            zeros_values = tf.zeros(ex_values.shape)\n",
    "            sok.assign(tmp_slot_var, ex_indices, zeros_values)\n",
    "    #Assign zeros is done\n",
    "    \n",
    "    # Load weight from sok dump\n",
    "    sok.load(\"./weight\", sok_vars, sok_optimizer)\n",
    "\n",
    "    # check var value before dump and var value after load\n",
    "    for sok_var in sok_vars:\n",
    "        ex_indices, ex_values = sok.export(sok_var)\n",
    "        sok_var_nps_new.append(ex_values.numpy())\n",
    "        sok_var_index_nps_new.append(ex_indices.numpy())\n",
    "    slot_states_list_new = []\n",
    "    slot_states_index_list_new = []\n",
    "    if have_state:\n",
    "        for slot_name in slot_names:\n",
    "            slot_vars_np_list_new = []\n",
    "            slot_vars_index_np_list_new = []\n",
    "            for sok_var in sok_vars:\n",
    "                slot_var = optimizer.get_slot(sok_var, slot_name)\n",
    "                ex_indices, ex_values = sok.export(slot_var)\n",
    "                slot_vars_np_list_new.append(ex_values.numpy())\n",
    "                slot_vars_index_np_list_new.append(ex_indices.numpy())\n",
    "            slot_states_list_new.append(slot_vars_np_list_new)\n",
    "            slot_states_index_list_new.append(slot_vars_index_np_list_new)\n",
    "\n",
    "    for i in range(len(sok_vars)):\n",
    "        var_sorted = np.argsort(sok_var_index_nps_raw[i])\n",
    "        var_pos = np.searchsorted(\n",
    "            sok_var_index_nps_raw[i][var_sorted], sok_var_index_nps_new[i]\n",
    "        )\n",
    "        remap_indices = var_sorted[var_pos]\n",
    "        tmp_sok_var_nps_raw = sok_var_nps_raw[i][remap_indices, :]\n",
    "\n",
    "        assert ((sok_var_nps_new[i] - tmp_sok_var_nps_raw) < 1e-5).all()\n",
    "\n",
    "    if have_state:\n",
    "        for i, tmp_slot_states_list in enumerate(slot_states_list_new):\n",
    "            for j, tmp_array in enumerate(tmp_slot_states_list):\n",
    "                index_raw = slot_states_index_list_raw[i][j]\n",
    "                index_new = slot_states_index_list_new[i][j]\n",
    "                var_sorted = np.argsort(index_raw)\n",
    "                var_pos = np.searchsorted(index_raw[var_sorted], index_new)\n",
    "                remap_indices = var_sorted[var_pos]\n",
    "                tmp_var_raw = slot_states_list_raw[i][j][remap_indices, :]\n",
    "                assert ((slot_states_list_new[i][j] - tmp_var_raw) < 1e-5).all()\n",
    "    print(\n",
    "        \"[SOK INFO] dump load distribute dynamic test {} optimizer successfully\".format(optimizer_id)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb71911a-2c88-4099-8e17-b4266d4794fe",
   "metadata": {},
   "source": [
    "Define a func to evaluate SOK dump and load using different TensorFlow optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "731ed264-8e5c-47ad-9cee-808eb01ef3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import horovod\n",
    "\n",
    "def training_func():\n",
    "    import os\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '4'\n",
    "    import tensorflow as tf\n",
    "    import horovod.tensorflow as hvd\n",
    "    import numpy as np\n",
    "    import sparse_operation_kit as sok\n",
    "\n",
    "    hvd.init()\n",
    "    gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    if gpus:\n",
    "        tf.config.experimental.set_visible_devices(gpus[hvd.local_rank()], \"GPU\")\n",
    "    sok.init()\n",
    "\n",
    "    #Here is SOK support optimizer\n",
    "    optimizers = [\n",
    "        tf.optimizers.SGD(learning_rate=1.0),\n",
    "        tf.optimizers.SGD(learning_rate=1.0, momentum=0.9),\n",
    "        tf.optimizers.Adamax(learning_rate=1.0, beta_1=0.9, beta_2=0.999),\n",
    "        tf.optimizers.Adadelta(learning_rate=1.0),\n",
    "        tf.optimizers.Adagrad(learning_rate=1.0),\n",
    "        tf.optimizers.Ftrl(learning_rate=1.0),\n",
    "    ]\n",
    "\n",
    "    #remove some tf stderr output\n",
    "    class suppress_stderr:\n",
    "        def __init__(self):\n",
    "            self.null_fd = os.open(os.devnull, os.O_RDWR)\n",
    "            self.save_fd = os.dup(2)\n",
    "\n",
    "        def __enter__(self):\n",
    "            os.dup2(self.null_fd, 2)\n",
    "\n",
    "        def __exit__(self, *_):\n",
    "            os.dup2(self.save_fd, 2)\n",
    "            os.close(self.null_fd)\n",
    "            os.close(self.save_fd)\n",
    "            \n",
    "    with suppress_stderr():\n",
    "        for optimizer_id, optimizer in enumerate(optimizers):\n",
    "            sok_dump_load_evaluate(optimizer,optimizer_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8221ea-4721-4071-b9cb-d71cf2ba8e0e",
   "metadata": {},
   "source": [
    "## Run With Horovod\n",
    "\n",
    "use horovod.run do 2 process task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f31d41c9-8c16-4a9b-9adc-4d3c9b0d7577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,0]<stdout>:[SOK INFO] Import /usr/local/lib/python3.10/dist-packages/merlin_sok-2.0.0-py3.10-linux-x86_64.egg/sparse_operation_kit/lib/libsparse_operation_kit.so\n",
      "[1,1]<stdout>:[SOK INFO] Import /usr/local/lib/python3.10/dist-packages/merlin_sok-2.0.0-py3.10-linux-x86_64.egg/sparse_operation_kit/lib/libsparse_operation_kit.so\n",
      "[1,0]<stdout>:[SOK INFO] Initialize finished, communication tool: horovod\n",
      "[1,1]<stdout>:[SOK INFO] Initialize finished, communication tool: horovod\n",
      "[1,0]<stdout>:[SOK INFO] SOK dump weight in path: ./weight  success!\n",
      "[1,1]<stdout>:[SOK INFO] SOK dump weight in path: ./weight  success!\n",
      "[1,1]<stdout>:[SOK INFO] SOK load weight from path: ./weight  success!\n",
      "[1,0]<stdout>:[SOK INFO] SOK load weight from path: ./weight  success!\n",
      "[1,0]<stdout>:[SOK INFO] dump load distribute dynamic test 0 optimizer successfully\n",
      "[1,1]<stdout>:[SOK INFO] dump load distribute dynamic test 0 optimizer successfully\n",
      "[1,0]<stdout>:[SOK INFO] SOK dump weight in path: ./weight  success!\n",
      "[1,1]<stdout>:[SOK INFO] SOK dump weight in path: ./weight  success!\n",
      "[1,0]<stdout>:[SOK INFO] SOK load weight from path: ./weight  success!\n",
      "[1,1]<stdout>:[SOK INFO] SOK load weight from path: ./weight  success!\n",
      "[1,0]<stdout>:[SOK INFO] dump load distribute dynamic test 1 optimizer successfully\n",
      "[1,1]<stdout>:[SOK INFO] dump load distribute dynamic test 1 optimizer successfully\n",
      "[1,0]<stdout>:[SOK INFO] SOK dump weight in path: ./weight  success!\n",
      "[1,1]<stdout>:[SOK INFO] SOK dump weight in path: ./weight  success!\n",
      "[1,0]<stdout>:[SOK INFO] SOK load weight from path: ./weight  success!\n",
      "[1,1]<stdout>:[SOK INFO] SOK load weight from path: ./weight  success!\n",
      "[1,1]<stdout>:[SOK INFO] dump load distribute dynamic test 2 optimizer successfully\n",
      "[1,0]<stdout>:[SOK INFO] dump load distribute dynamic test 2 optimizer successfully\n",
      "[1,0]<stdout>:[SOK INFO] SOK dump weight in path: ./weight  success!\n",
      "[1,1]<stdout>:[SOK INFO] SOK dump weight in path: ./weight  success!\n",
      "[1,1]<stdout>:[SOK INFO] SOK load weight from path: ./weight  success!\n",
      "[1,0]<stdout>:[SOK INFO] SOK load weight from path: ./weight  success!\n",
      "[1,0]<stdout>:[SOK INFO] dump load distribute dynamic test 3 optimizer successfully\n",
      "[1,1]<stdout>:[SOK INFO] dump load distribute dynamic test 3 optimizer successfully\n",
      "[1,0]<stdout>:[SOK INFO] SOK dump weight in path: ./weight  success!\n",
      "[1,1]<stdout>:[SOK INFO] SOK dump weight in path: ./weight  success!\n",
      "[1,0]<stdout>:[SOK INFO] SOK load weight from path: ./weight  success!\n",
      "[1,1]<stdout>:[SOK INFO] SOK load weight from path: ./weight  success!\n",
      "[1,1]<stdout>:[SOK INFO] dump load distribute dynamic test 4 optimizer successfully\n",
      "[1,0]<stdout>:[SOK INFO] dump load distribute dynamic test 4 optimizer successfully\n",
      "[1,0]<stdout>:[SOK INFO] SOK dump weight in path: ./weight  success!\n",
      "[1,1]<stdout>:[SOK INFO] SOK dump weight in path: ./weight  success!\n",
      "[1,0]<stdout>:[SOK INFO] SOK load weight from path: ./weight  success!\n",
      "[1,1]<stdout>:[SOK INFO] SOK load weight from path: ./weight  success!\n",
      "[1,0]<stdout>:[SOK INFO] dump load distribute dynamic test 5 optimizer successfully\n",
      "[1,1]<stdout>:[SOK INFO] dump load distribute dynamic test 5 optimizer successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horovod.run(training_func, np=2, verbose=False, disable_cache=True, use_mpi=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "285201f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 292224\n",
      "-rw-r--r-- 1 nobody nogroup 14065960 May 30 02:12 sok_dynamic_Variable_0_0-Adam-m\n",
      "-rw-r--r-- 1 nobody nogroup 14065960 May 30 02:12 sok_dynamic_Variable_0_0-Adam-v\n",
      "-rw-r--r-- 1 nobody nogroup   218880 May 30 02:31 sok_dynamic_Variable_0_0-key\n",
      "-rw-r--r-- 1 nobody nogroup 13989672 May 30 02:31 sok_dynamic_Variable_0_0-weight\n",
      "-rw-r--r-- 1 nobody nogroup 13922600 May 30 02:31 sok_dynamic_Variable_10_0-Ftrl-accumulator\n",
      "-rw-r--r-- 1 nobody nogroup 13922600 May 30 02:31 sok_dynamic_Variable_10_0-Ftrl-linear\n",
      "-rw-r--r-- 1 nobody nogroup   217832 May 30 02:31 sok_dynamic_Variable_10_0-key\n",
      "-rw-r--r-- 1 nobody nogroup 13922600 May 30 02:31 sok_dynamic_Variable_10_0-weight\n",
      "-rw-r--r-- 1 nobody nogroup   113752 May 30 02:31 sok_dynamic_Variable_11_0-Ftrl-accumulator\n",
      "-rw-r--r-- 1 nobody nogroup   113752 May 30 02:31 sok_dynamic_Variable_11_0-Ftrl-linear\n",
      "-rw-r--r-- 1 nobody nogroup    57024 May 30 02:31 sok_dynamic_Variable_11_0-key\n",
      "-rw-r--r-- 1 nobody nogroup   113752 May 30 02:31 sok_dynamic_Variable_11_0-weight\n",
      "-rw-r--r-- 1 nobody nogroup   113432 May 30 02:12 sok_dynamic_Variable_1_0-Adam-m\n",
      "-rw-r--r-- 1 nobody nogroup   113432 May 30 02:12 sok_dynamic_Variable_1_0-Adam-v\n",
      "-rw-r--r-- 1 nobody nogroup    56864 May 30 02:31 sok_dynamic_Variable_1_0-key\n",
      "-rw-r--r-- 1 nobody nogroup   113432 May 30 02:31 sok_dynamic_Variable_1_0-weight\n",
      "-rw-r--r-- 1 nobody nogroup 13933352 May 30 02:12 sok_dynamic_Variable_2_0-Adadelta-accum_grad\n",
      "-rw-r--r-- 1 nobody nogroup 13933352 May 30 02:12 sok_dynamic_Variable_2_0-Adadelta-accum_var\n",
      "-rw-r--r-- 1 nobody nogroup 14019880 May 30 02:31 sok_dynamic_Variable_2_0-SGD-momentum\n",
      "-rw-r--r-- 1 nobody nogroup   219352 May 30 02:31 sok_dynamic_Variable_2_0-key\n",
      "-rw-r--r-- 1 nobody nogroup 14019880 May 30 02:31 sok_dynamic_Variable_2_0-weight\n",
      "-rw-r--r-- 1 nobody nogroup   114920 May 30 02:12 sok_dynamic_Variable_3_0-Adadelta-accum_grad\n",
      "-rw-r--r-- 1 nobody nogroup   114920 May 30 02:12 sok_dynamic_Variable_3_0-Adadelta-accum_var\n",
      "-rw-r--r-- 1 nobody nogroup   114088 May 30 02:31 sok_dynamic_Variable_3_0-SGD-momentum\n",
      "-rw-r--r-- 1 nobody nogroup    57192 May 30 02:31 sok_dynamic_Variable_3_0-key\n",
      "-rw-r--r-- 1 nobody nogroup   114088 May 30 02:31 sok_dynamic_Variable_3_0-weight\n",
      "-rw-r--r-- 1 nobody nogroup 14028072 May 30 02:12 sok_dynamic_Variable_4_0-Adagrad-accumulator\n",
      "-rw-r--r-- 1 nobody nogroup 14063912 May 30 02:31 sok_dynamic_Variable_4_0-Adam-m\n",
      "-rw-r--r-- 1 nobody nogroup 14063912 May 30 02:31 sok_dynamic_Variable_4_0-Adam-v\n",
      "-rw-r--r-- 1 nobody nogroup   220040 May 30 02:31 sok_dynamic_Variable_4_0-key\n",
      "-rw-r--r-- 1 nobody nogroup 14063912 May 30 02:31 sok_dynamic_Variable_4_0-weight\n",
      "-rw-r--r-- 1 nobody nogroup   113528 May 30 02:12 sok_dynamic_Variable_5_0-Adagrad-accumulator\n",
      "-rw-r--r-- 1 nobody nogroup   114040 May 30 02:31 sok_dynamic_Variable_5_0-Adam-m\n",
      "-rw-r--r-- 1 nobody nogroup   114040 May 30 02:31 sok_dynamic_Variable_5_0-Adam-v\n",
      "-rw-r--r-- 1 nobody nogroup    57168 May 30 02:31 sok_dynamic_Variable_5_0-key\n",
      "-rw-r--r-- 1 nobody nogroup   114040 May 30 02:31 sok_dynamic_Variable_5_0-weight\n",
      "-rw-r--r-- 1 nobody nogroup 13987112 May 30 02:31 sok_dynamic_Variable_6_0-Adadelta-accum_grad\n",
      "-rw-r--r-- 1 nobody nogroup 13987112 May 30 02:31 sok_dynamic_Variable_6_0-Adadelta-accum_var\n",
      "-rw-r--r-- 1 nobody nogroup 13902120 May 30 02:12 sok_dynamic_Variable_6_0-Ftrl-accumulator\n",
      "-rw-r--r-- 1 nobody nogroup 13902120 May 30 02:12 sok_dynamic_Variable_6_0-Ftrl-linear\n",
      "-rw-r--r-- 1 nobody nogroup   218840 May 30 02:31 sok_dynamic_Variable_6_0-key\n",
      "-rw-r--r-- 1 nobody nogroup 13987112 May 30 02:31 sok_dynamic_Variable_6_0-weight\n",
      "-rw-r--r-- 1 nobody nogroup   113448 May 30 02:31 sok_dynamic_Variable_7_0-Adadelta-accum_grad\n",
      "-rw-r--r-- 1 nobody nogroup   113448 May 30 02:31 sok_dynamic_Variable_7_0-Adadelta-accum_var\n",
      "-rw-r--r-- 1 nobody nogroup   113448 May 30 02:12 sok_dynamic_Variable_7_0-Ftrl-accumulator\n",
      "-rw-r--r-- 1 nobody nogroup   113448 May 30 02:12 sok_dynamic_Variable_7_0-Ftrl-linear\n",
      "-rw-r--r-- 1 nobody nogroup    56872 May 30 02:31 sok_dynamic_Variable_7_0-key\n",
      "-rw-r--r-- 1 nobody nogroup   113448 May 30 02:31 sok_dynamic_Variable_7_0-weight\n",
      "-rw-r--r-- 1 nobody nogroup 13948200 May 30 02:31 sok_dynamic_Variable_8_0-Adagrad-accumulator\n",
      "-rw-r--r-- 1 nobody nogroup   218232 May 30 02:31 sok_dynamic_Variable_8_0-key\n",
      "-rw-r--r-- 1 nobody nogroup 13948200 May 30 02:31 sok_dynamic_Variable_8_0-weight\n",
      "-rw-r--r-- 1 nobody nogroup   113848 May 30 02:31 sok_dynamic_Variable_9_0-Adagrad-accumulator\n",
      "-rw-r--r-- 1 nobody nogroup    57072 May 30 02:31 sok_dynamic_Variable_9_0-key\n",
      "-rw-r--r-- 1 nobody nogroup   113848 May 30 02:31 sok_dynamic_Variable_9_0-weight\n"
     ]
    }
   ],
   "source": [
    "!ls -l ./weight"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
