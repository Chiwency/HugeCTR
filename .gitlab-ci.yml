include:
#  - remote: 'https://gitlab.com/yesolutions/gitlab-ci-templates/raw/main/templates/pre-commit-autofix.yaml'
  - project: "dl/devops/gitlab-ci-slurm"
    ref: master
    file: "/.gitlab-ci.yml"
  - /ci/common.yml
  - /ci/template.yml
  - /ci/benchmark.yml
  - /ci/rules.gitlab_ci.yml

nightly_build_all:
  extends: .build_nightly
  variables:
    REMOTE_REPO: https://github.com/NVIDIA-Merlin/Merlin.git
    DST_IMAGE: ${IMAGE_ALL}
    DOCKER_FILE: dockerfile.ctr
    BUILD_ARGS: --build-arg HUGECTR_DEV_MODE=true

nightly_build_sok_tf2:
  extends: .build_nightly
  variables:
    REMOTE_REPO: https://github.com/NVIDIA-Merlin/Merlin.git
    DST_IMAGE: ${IMAGE_SOK_TF2}
    DOCKER_FILE: dockerfile.tf
    BUILD_ARGS: --build-arg HUGECTR_DEV_MODE=true

nightly_build_sok_tf1:
  extends: .build_nightly_tf1
  variables:
    DST_IMAGE: ${IMAGE_SOK_TF1}
    DOCKER_FILE: Dockerfile.sok1
    BUILD_ARGS: --build-arg HUGECTR_DEV_MODE=true

nightly_build_unified_container.tf:
  extends: .build_nightly
  variables:
    REMOTE_REPO: https://github.com/NVIDIA-Merlin/Merlin.git
    DST_IMAGE: ${CI_REGISTRY}/dl/hugectr/hugectr:unified.tf.latest
    DOCKER_FILE: dockerfile.tf
    BUILD_ARGS: --build-arg _CI_JOB_TOKEN=${RD_CI_JOB_TOKEN} --build-arg _HUGECTR_REPO=gitlab-master.nvidia.com/dl/hugectr/hugectr.git --build-arg HUGECTR_VER=${CI_COMMIT_BRANCH}

nightly_build_unified_container.ctr:
  extends: .build_nightly
  variables:
    REMOTE_REPO: https://github.com/NVIDIA-Merlin/Merlin.git
    DST_IMAGE: ${CI_REGISTRY}/dl/hugectr/hugectr:unified.ctr.latest
    DOCKER_FILE: dockerfile.ctr
    BUILD_ARGS: --build-arg _CI_JOB_TOKEN=${RD_CI_JOB_TOKEN} --build-arg _HUGECTR_REPO=gitlab-master.nvidia.com/dl/hugectr/hugectr.git --build-arg HUGECTR_VER=${CI_COMMIT_BRANCH} --build-arg _HUGECTR_BACKEND_REPO=gitlab-master.nvidia.com/dl/hugectr/hugectr_inference_backend.git --build-arg HUGECTR_BACKEND_VER=hugectr_performance_test

nightly_build_optimized:
  extends: .build_nightly
  variables:
    REMOTE_REPO: https://${RD_CI_JOB_TOKEN}gitlab-master.nvidia.com/dl/mlperf/optimized.git
    DST_IMAGE: ${IMAGE_OPTIMIZED}
    DOCKER_FILE: Dockerfile
    BUILD_ARGS: --build-arg RELEASE=false --build-arg FROM_IMAGE_NAME=gitlab-master.nvidia.com:5005/dl/dgx/pytorch:master-py3-devel
    OPTIMIZED: 1
  rules:
    - if: $NIGHTLY_OPTIMIZED == "1"
      when: always
    - when: never

build_optimized:
  extends: .build_nightly
  variables:
    REMOTE_REPO: https://${RD_CI_JOB_TOKEN}gitlab-master.nvidia.com/dl/mlperf/optimized.git
    DST_IMAGE: ${IMAGE_OPTIMIZED}.${CI_PIPELINE_ID}
    DOCKER_FILE: Dockerfile
    BUILD_ARGS: --build-arg FROM_IMAGE_NAME=gitlab-master.nvidia.com:5005/dl/dgx/pytorch:master-py3-devel
    OPTIMIZED: 1
  rules:
    - if: $NIGHTLY_OPTIMIZED == "1"
      when: always
    - when: never

### Stage: build
format_check_python:
  extends: .python_format
  variables:
    EXCLUDE: "third_party|docs|notebooks|tutorial"

format_check_clang:
  extends: .clang_format
  variables:
    EXCLUDE: ./third_party
    STYLE: file
    EXECUTABLE: clang-format14
    EXTENSIONS: "h,hpp,cpp,cu,cuh"

codespell_check:
  extends: .codespell_check
  variables:
    PRE_COM_IMAGE: registry.gitlab.com/yesolutions/docker-pre-commit

build_train_single_node:
  extends: .build_hugectr
  variables:
    FROM_IMAGE: ${IMAGE_ALL}
    DST_IMAGE: $TRAIN_IMAGE_VERSIONED
    CMAKE_OPTION: "-DCMAKE_BUILD_TYPE=Release -DKEY_HIT_RATIO=ON -DSM=\"60;61;70;75;80;90\" -DCLANGFORMAT=OFF"
    BUILD_HUGECTR: 1
    BUILD_HUGECTR2ONNX: 1

build_train_single_node_latest:
  extends: .build_hugectr_daily
  variables:
    FROM_IMAGE: ${MERLIN_NIGHTLY_DEVEL}
    DST_IMAGE: $TRAIN_IMAGE_VERSIONED_LATEST
    CMAKE_OPTION: "-DCMAKE_BUILD_TYPE=Release -DKEY_HIT_RATIO=ON -DSM=\"60;61;70;75;80;90\" -DCLANGFORMAT=OFF"
    BUILD_HUGECTR: 1
    BUILD_HUGECTR2ONNX: 1

build_train_single_node_with_hdfs_minimal:
  extends: .build_hugectr
  variables:
    FROM_IMAGE: ${IMAGE_ALL}
    DST_IMAGE: $TRAIN_IMAGE_VERSIONED_WITH_HDFS_MINI
    CMAKE_OPTION: "-DCMAKE_BUILD_TYPE=Release -DKEY_HIT_RATIO=ON -DSM=\"60;61;70;75;80;90\" -DCLANGFORMAT=OFF -DENABLE_HDFS=MINIMAL"
    BUILD_HUGECTR: 1
    BUILD_HUGECTR2ONNX: 1

build_train_single_node_with_hdfs_full:
  extends: .build_hugectr_daily
  variables:
    FROM_IMAGE: ${IMAGE_ALL}
    DST_IMAGE: $TRAIN_IMAGE_VERSIONED_WITH_HDFS
    CMAKE_OPTION: "-DCMAKE_BUILD_TYPE=Release -DKEY_HIT_RATIO=ON -DSM=\"60;61;70;75;80;90\" -DCLANGFORMAT=OFF -DENABLE_HDFS=ON"
    BUILD_HUGECTR: 1
    BUILD_HUGECTR2ONNX: 1

build_train_single_node_with_s3:
  extends: .build_hugectr
  variables:
    FROM_IMAGE: ${IMAGE_ALL}
    DST_IMAGE: ${TRAIN_IMAGE_VERSIONED_WITH_S3}
    CMAKE_OPTION: "-DCMAKE_BUILD_TYPE=Release -DKEY_HIT_RATIO=ON -DSM=\"60;61;70;75;80;90\" -DCLANGFORMAT=OFF -DENABLE_S3=ON"
    BUILD_HUGECTR: 1
    BUILD_HUGECTR2ONNX: 1

build_train_single_node_with_gcs:
  extends: .build_hugectr
  variables:
    FROM_IMAGE: ${IMAGE_ALL}
    DST_IMAGE: ${TRAIN_IMAGE_VERSIONED_WITH_GCS}
    CMAKE_OPTION: "-DCMAKE_BUILD_TYPE=Release -DKEY_HIT_RATIO=ON -DSM=\"60;61;70;75;80;90\" -DCLANGFORMAT=OFF -DENABLE_GCS=ON"
    BUILD_HUGECTR: 1
    BUILD_HUGECTR2ONNX: 1

build_train_multi_node:
  extends: .build_hugectr
  variables:
    FROM_IMAGE: ${IMAGE_ALL}
    DST_IMAGE: $TRAIN_IMAGE_MULTINODE_VERSIONED
    CMAKE_OPTION: "-DCMAKE_BUILD_TYPE=Release -DKEY_HIT_RATIO=ON -DENABLE_MULTINODES=ON -DSM=\"60;61;70;75;80;90\" -DCLANGFORMAT=OFF"
    BUILD_HUGECTR: 1

build_train_inference:
  extends: .build_hugectr
  variables:
    FROM_IMAGE: ${IMAGE_ALL}
    DST_IMAGE: $TRAIN_INFER_IMAGE_VERSIONED
    CMAKE_OPTION: "-DENABLE_INFERENCE=ON -DCMAKE_BUILD_TYPE=Release -DSM=\"60;61;70;75;80;90\" -DCLANGFORMAT=OFF"
    BUILD_HUGECTR: 1

### Stage: test
build_inference:
  extends: .build_hugectr
  variables:
    FROM_IMAGE: ${IMAGE_ALL}
    DST_IMAGE: $INFER_IMAGE_VERSIONED
    CMAKE_OPTION: "-DENABLE_INFERENCE=ON -DCMAKE_BUILD_TYPE=Release -DSM=\"70;75;80;90\" -DCLANGFORMAT=OFF"
    BUILD_HUGECTR: 1
    BUILD_HPS_BACKEND: 1
    HUGECTR_BACKEND_VER: main
    TRITON_BRANCH: ${TARGET_TRITON_BRANCH}

build_sok_tf2:
  extends: .build_sok
  variables:
    FROM_IMAGE: ${IMAGE_ALL}
    DST_IMAGE: $SOK_IMAGE_VERSIONED_TF2
    CMAKE_OPTION: "-DSM=\"60;61;70;75;80;90\""
    BUILD_SOK: 1

build_sok_tf1:
  extends: .build_sok
  variables:
    FROM_IMAGE: ${IMAGE_SOK_TF1}
    DST_IMAGE: $SOK_IMAGE_VERSIONED_TF1
    CMAKE_OPTION: "-DSM=\"60;61;70;75;80;90\""
    BUILD_SOK: 1

build_hugectr_hps_trt_plugin:
  extends: .build_hugectr
  variables:
    FROM_IMAGE: ${IMAGE_ALL}
    DST_IMAGE: $HUGECTR_TRT_IMAGE_VERSIONED
    CMAKE_OPTION: "-DCMAKE_BUILD_TYPE=Release -DKEY_HIT_RATIO=ON -DSM=\"60;61;70;75;80;90\" -DCLANGFORMAT=OFF"
    BUILD_HUGECTR: 1
    BUILD_HUGECTR2ONNX: 1
    BUILD_TRT_PLUGIN: 1
    TRT_CMAKE_OPTION: "-DSM=\"70;75;80;90\""
    #BUILD_HPS_BACKEND: 1
    #HUGECTR_BACKEND_VER: main
    #TRITON_BRANCH: ${TRITON_BRANCH}

build_tf_hps_trt_plugin:
  extends: .build_hugectr
  variables:
    FROM_IMAGE: ${IMAGE_ALL}
    DST_IMAGE: $TF_TRT_IMAGE_VERSIONED
    BUILD_TF_PLUGIN: 1
    BUILD_TRT_PLUGIN: 1
    TRT_CMAKE_OPTION: "-DSM=\"70;75;80;90\""
    #BUILD_HPS_BACKEND: 1
    #HUGECTR_BACKEND_VER: main
    #TRITON_BRANCH: r22.11

build_pytorch_hps_trt_plugin:
  extends: .build_hugectr
  variables:
    FROM_IMAGE: ${IMAGE_ALL}
    DST_IMAGE: $PYTORCH_TRT_IMAGE_VERSIONED
    BUILD_TORCH_PLUGIN: 1
    BUILD_TRT_PLUGIN: 1
    TRT_CMAKE_OPTION: "-DSM=\"70;75;80;90\""
    #BUILD_HPS_BACKEND: 1
    #HUGECTR_BACKEND_VER: main
    #TRITON_BRANCH: r22.11

# Check cluster busy or not
check_cluster_status:
  extends: .trigger:rules:selene
  stage: pre_test
  tags:
    - nvidia.com/cuda.driver.major=470
    - $BUILD_TAG
  script:
    - docker login -u ${CI_PRIVATE_USER} -p "${CI_PRIVATE_KEY}" "${CI_REGISTRY}"
    - docker pull ${CONT}
    - RC=0
    - docker run -d --rm --name cluster_idle_${CI_PIPELINE_ID} ${EXTRA_DOCKER_RUN_ARGS} ${CONT} sleep infinity
    - docker exec cluster_idle_${CI_PIPELINE_ID} bash -cx "python get_selene_runner_status.py --quota ${SELENE_QUEUE_QUOTA} --token \"${CLUSTER_TOKEN}\" " || RC=$?
    - echo "$RC"
    - echo "NEW_CI_CONCURRENT_ID=${CI_CONCURRENT_ID}" >> other_param.env
    - if [[ $RC == 0 ]]; then
      echo "Run jobs in draco-oci cluster!";
      cp ./ci/draco-oci/ci.yml ./test-ci.yml;
      echo "NEW_SBATCH_OTHER_PARAMS=" >> other_param.env;
      else
      echo "Run jobs in other cluster!";
      cp ./ci/dracorno/ci.yml ./test-ci.yml;
      echo "NEW_SBATCH_OTHER_PARAMS=--nv-meta ml-model.hugectr --gpus-per-node=8" >> other_param.env;
      fi
    - cat other_param.env
  artifacts:
    paths:
      - ./test-ci.yml
    reports:
      dotenv: other_param.env
  variables:
    CONT: gitlab-master.nvidia.com:5005/dl/hugectr/hugectr/emma:get_selene_status_new
  allow_failure: false
  timeout: 15 minutes

trigger_test_pipeline:
  extends: .trigger:rules:selene
  stage:
    test
  needs:
    - check_cluster_status
  trigger:
    include:
      - artifact: test-ci.yml
        job: check_cluster_status
    strategy: depend
  variables:
    PARENT_SOURCE: ${CI_PIPELINE_SOURCE}
    PARENT_PIPELINE_ID: ${CI_PIPELINE_ID}
    GCS_ACCESS_FILE: ${GCS_ACCESS_FILE}
    PARENT_GCS_ACCESS_FILE: ${GCS_ACCESS_FILE}
    SBATCH_OTHER_PARAMS: ${NEW_SBATCH_OTHER_PARAMS}

criteo_multi_node:
  extends: .cluster_test_job_daily
  needs:
    - build_train_multi_node
  variables:
    CONT: $TRAIN_IMAGE_MULTINODE_VERSIONED
    MOUNTS: ${DRACO_OCI_DATASET}:${DATASET_MOUNT}
    CI_SLURM_TIME: "00:15:00"
    CI_SLURM_NODES: 2
    SLURM_JOB_NUM_NODES: 2
    TEST_CMD: ./ci/integration_test/criteo/criteo_multi_node.sub

dlrm_dcnv2_benchmark_8node:
  extends: .cluster_test_job_daily
  needs:
    - build_train_multi_node
  variables:
    CONT: $TRAIN_IMAGE_MULTINODE_VERSIONED
    MOUNTS: /lustre/fsw/portfolios/coreai/projects/coreai_devtech_all/hugectr/hpc-hugectr/dlrm/datasets/criteo_multihot_raw:/data,/lustre/fsw/portfolios/coreai/projects/coreai_devtech_all/hugectr/hpc-hugectr/dlrm/datasets/criteo_multihot_raw:/data_val
    CI_SLURM_TIME: "02:00:00"
    CI_SLURM_NODES: 8
    SLURM_JOB_NUM_NODES: 8
    TEST_CMD: ./ci/integration_test/dlrm/train_dcnv2_8node.sub

wdl_multi_gpu:
  extends: .cluster_test_job_daily                                                     # test on selene needs to extend .cluster_test_job
  needs:
    - build_train_single_node
  variables:
    CONT: $TRAIN_IMAGE_VERSIONED                                                 # image name
    MOUNTS: ${DRACO_OCI_DATASET_NEW_CRITEO}:${DATASET_MOUNT}                                          # mount
    CI_SLURM_TIME: "00:15:00"                                                         # estimate job time. Less time, higher priority
    TEST_CMD: ./ci/integration_test/wdl/wdl_daily.sub

deepfm_multi_gpu:
  extends: .cluster_test_job_daily
  needs:
    - build_train_single_node
  variables:
    CONT: $TRAIN_IMAGE_VERSIONED
    MOUNTS: ${DRACO_OCI_DATASET}:${DATASET_MOUNT}
    CI_SLURM_TIME: "00:15:00"
    TEST_CMD: ./ci/integration_test/deepfm/deepfm_daily.sub

dcn_multi_node:
  extends: .cluster_test_job_daily
  needs:
    - build_train_multi_node
  variables:
    CONT: $TRAIN_IMAGE_MULTINODE_VERSIONED
    MOUNTS: ${DRACO_OCI_DATASET}:${DATASET_MOUNT}
    CI_SLURM_TIME: "01:00:00"
    CI_SLURM_NODES: 4
    SLURM_JOB_NUM_NODES: 4
    TEST_CMD: ./ci/integration_test/dcn/dcn_multi_node.sub

py_low_level:
  extends: .cluster_test_job_daily
  needs:
    - build_train_single_node
  variables:
    CONT: $TRAIN_IMAGE_VERSIONED
    MOUNTS: /raid:/raid,${DRACO_OCI_DATASET_NEW_CRITEO}:${NEW_CRITEO_MOUNT}
    CI_SLURM_TIME: "01:00:00"
    TEST_CMD: ./ci/integration_test/py_interface/py_low_level.sub

ebc_single_node:
  extends: .cluster_test_job_daily
  needs:
    - build_train_single_node
  variables:
    CONT: $TRAIN_IMAGE_VERSIONED
    MOUNTS: ${DRACO_OCI_DATASET_NEW_CRITEO}:${DATASET_MOUNT},/raid:/raid
    CI_SLURM_TIME: "02:00:00"
    TEST_CMD: ./ci/integration_test/ebc/ebc.sub

py_multi_node:
  extends: .cluster_test_job_daily
  needs:
    - build_train_multi_node
  variables:
    CONT: $TRAIN_IMAGE_MULTINODE_VERSIONED
    MOUNTS: ${DRACO_OCI_DATASET}:${DATASET_MOUNT}
    CI_SLURM_TIME: "00:15:00"
    CI_SLURM_NODES: 4
    SLURM_JOB_NUM_NODES: 4
    TEST_CMD: ./ci/integration_test/py_interface/py_multi_node.sub

inference_benchmark:
  extends: .cluster_test_job_daily
  needs:
    - build_inference
  before_script:
    - export BZ=1
    - export MIXED_PRECISION=FP32
  variables:
    CONT: $INFER_IMAGE_VERSIONED
    MOUNTS: /lustre/fsw/portfolios/coreai/projects/coreai_devtech_all/hugectr/hpc-hugectr/inference/dlrm_regression/dlrm/1:/model/dlrm/1,/lustre/fsw/portfolios/coreai/projects/coreai_devtech_all/hugectr/hpc-hugectr/keynote_inference/perf_data:/perf_data
    WORKDIR: /workdir
    CI_SLURM_TIME: "00:15:00"
    TEST_CMD: ./ci/benchmark/inference_benchmark/run.sub

inference_ps_test:
  extends: .computelab_test_job_daily
  allow_failure: false
  stage: test
  needs:
    - build_inference
  script:
    - export CONT=${INFER_IMAGE_VERSIONED}
    - bash ./ci/integration_test/inference/ps_test.sh

inference_embedding_cache_update_test:
  extends: .computelab_test_job_daily
  allow_failure: false
  stage: test
  needs:
    - build_inference
  script:
    - export CONT=${INFER_IMAGE_VERSIONED}
    - bash ./ci/integration_test/inference/embedding_cache_update_test.sh

#hdfs backend test
hdfs_backend_test:
  extends: .computelab_test_job_daily
  needs:
    - build_train_single_node_with_hdfs_full
  script:
    - export CONT=${TRAIN_IMAGE_VERSIONED_WITH_HDFS}
    - bash ./ci/integration_test/hdfs/hdfs_backend_test.sh

continuous_training_inference:
  extends: .test_local
  variables:
    CONT: ${UNIFIED_CTR_LATEST}
    MOUNTS: -v /opt/ci/demo:/scripts -v /opt/ci/wdl_infer:/wdl_infer
    CMD: "apt update -y --fix-missing && apt install bc && cd /scripts && bash run_continuouse_test.sh"

# NVT regression
e2e_nvt_regression_test:
  extends: .cluster_test_job_daily
  needs:
    - build_train_single_node_latest
  variables:
    CONT: $TRAIN_IMAGE_VERSIONED_LATEST
    MOUNTS: /lustre/fsw/portfolios/coreai/projects/coreai_devtech_all/hugectr/hpc-hugectr/criteo_1TB/day_1:/workdir/tools/day_1,/lustre/fsw/portfolios/coreai/projects/coreai_devtech_all/hugectr/hpc-hugectr/inference/nvt_regression:/workdir/samples/din/raw_data,/lustre/fsw/portfolios/coreai/projects/coreai_devtech_all/hugectr/hpc-hugectr/criteo_1TB/day_0:/dir/to/criteo/day_0
    CI_SLURM_TIME: "01:00:00"
    TEST_CMD: ./ci/integration_test/nvt/nvt_regression_test.sub

nb_hps_demo:
  extends: .cluster_test_job_daily
  needs:
    - build_train_single_node
  variables:
    CONT: $TRAIN_IMAGE_VERSIONED
    CI_SLURM_TIME: "00:45:00"
    TEST_CMD: ./ci/integration_test/notebooks/hps_demo.sub

test_sok_pypi:
  extends: .cluster_test_job_daily
  needs:
    - build_sok_tf2
  variables:
    CONT: $SOK_IMAGE_VERSIONED_TF2
    CI_SLURM_TIME: "00:30:00"
    TEST_CMD: ./ci/integration_test/sok/test_sok_pypi.sub

wdl_check:
  # Push logs to gitlab
  extends: .cluster_post_test_job_daily
  needs:
    - wdl_multi_gpu
  variables:
    CONT: $TRAIN_IMAGE_VERSIONED
    MOUNTS:  ${DRACO_OCI_LOGDIR}/wdl_multi_gpu:/logs
    CI_SLURM_TIME: "00:15:00"
    TEST_CMD: ./ci/post_test/check_wdl.sub

inference_benchmark_check:
  extends: .cluster_post_test_job_daily
  needs:
    - inference_benchmark
    - build_train_single_node
  variables:
    CONT: $TRAIN_IMAGE_VERSIONED
    MOUNTS:  ${DRACO_OCI_LOGDIR}/inference_benchmark:/logs
    CI_SLURM_TIME: "00:15:00"
    TEST_CMD: ./ci/post_test/check_inference_benchmark.sub

inference_cpu_memory_usage:
  extends: .cluster_test_job_daily
  needs:
    - build_inference
  before_script:
    - export BZ=1
    - export MIXED_PRECISION=FP32
    - mkdir -p ${DRACO_OCI_LOGDIR}/inference_cpu_memory
  variables:
    CONT: $INFER_IMAGE_VERSIONED
    MOUNTS: /lustre/fsw/portfolios/coreai/projects/coreai_devtech_all/hugectr/hpc-hugectr/inference/dlrm_regression/dlrm/1:/model/dlrm/1,${DRACO_OCI_LOGDIR}/inference_cpu_memory:/logs
    WORKDIR: /workdir
    CI_SLURM_TIME: "00:30:00"
    TEST_CMD: ./ci/benchmark/hps_memory_check/run.sub

inference_CPU_Memory_check:
  extends: .cluster_post_test_job_daily
  needs:
    - inference_cpu_memory_usage
    - build_train_single_node
  variables:
    CONT: $TRAIN_IMAGE_VERSIONED
    MOUNTS: ${DRACO_OCI_LOGDIR}/inference_cpu_memory:/logs
    CI_SLURM_TIME: "00:15:00"
    TEST_CMD: ./ci/post_test/check_cpu_usage.sub

dlrm_dcnv2_8node_check:
  # Push logs to gitlab
  extends: .cluster_post_test_job_daily
  needs:
    - dlrm_dcnv2_benchmark_8node
  variables:
    CONT: $TRAIN_IMAGE_VERSIONED
    MOUNTS: ${DRACO_OCI_LOGDIR}/dlrm_dcnv2_benchmark_8node:/logs
    CI_SLURM_TIME: "00:15:00"
    TEST_CMD: ./ci/post_test/check_dcnv2_dlrm_8node.sub

# rm_logs:
#   extends: .cluster_test_job
#   variables:
#     GPFSFOLDER: "$LOGDIR"
#     GIT_CLONE_PATH: /lustre/fsw/devtech/hpc-hugectr/hugectr-ci/$CI_CONCURRENT_ID/$CI_PROJECT_NAME
#     CONT: $TRAIN_IMAGE_VERSIONED
#     MOUNTS: /lustre/fsw/devtech:/logs
#     SLURM_ACCOUNT: devtech
#     WALLTIME: "00:15:00"
#     DGXNNODES: 1
#     TEST_CMD: ./ci/common/clean_logs.sub

